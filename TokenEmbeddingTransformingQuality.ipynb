{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9de04f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src import GenerateVectors\n",
    "\n",
    "n_sents = 1012\n",
    "\n",
    "outdir = \"generated/\"\n",
    "\n",
    "model_name_1 = \"models/opus-mt-NORTH_EU-NORTH_EU\"\n",
    "model_name_2 = \"models/opus-mt-SCANDINAVIA-SCANDINAVIA\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd11edf",
   "metadata": {},
   "source": [
    "### Load or generate embeddings for FLORES-200 devtest dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0664cbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_or_load(test_dataset, save_prefix):\n",
    "    return GenerateVectors.generate_or_load(\n",
    "        test_dataset,\n",
    "        n_sents,\n",
    "        model_name_1,\n",
    "        model_name_2,\n",
    "        outdir,\n",
    "        save_prefix)\n",
    "\n",
    "sv_token_embedings_1, sv_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/swe_Latn.devtest\"], \"flores_sv\")\n",
    "da_token_embedings_1, da_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/dan_Latn.devtest\"], \"flores_da\")\n",
    "nb_token_embedings_1, nb_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/nob_Latn.devtest\"], \"flores_nb\")\n",
    "nn_token_embedings_1, nn_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/nno_Latn.devtest\"], \"flores_nn\")\n",
    "fo_token_embedings_1, fo_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/fao_Latn.devtest\"], \"flores_fo\")\n",
    "is_token_embedings_1, is_token_embedings_2 = generate_or_load([\"data/flores200_dataset/devtest/isl_Latn.devtest\"], \"flores_is\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d98f9a",
   "metadata": {},
   "source": [
    "### Load in the regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a04ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import jdata as jd\n",
    "\n",
    "# Load the MLP conf from the json file\n",
    "mlp_conf = jd.load(\"models/MLP_regressor_8192_sv_500k_opus-mt-NORTH_EU-NORTH_EU_to_opus-mt-SCANDINAVIA-SCANDINAVIA.json\")\n",
    "\n",
    "# Initialize MLP regressor\n",
    "mlp_regressor = MLPRegressor(random_state=1, hidden_layer_sizes=(8192))\n",
    "\n",
    "# Load in the regressor parameters and conf\n",
    "mlp_regressor.intercepts_ = mlp_conf[\"intercepts_\"]\n",
    "mlp_regressor.coefs_ = mlp_conf[\"coefs_\"]\n",
    "mlp_regressor.n_layers_ = mlp_conf[\"n_layers_\"]\n",
    "mlp_regressor.out_activation_ = mlp_conf[\"out_activation_\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306f7c0d",
   "metadata": {},
   "source": [
    "### Measure cosine similarity on FLORES-200 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "309afce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity when testing MLP on Flores 200 devtest dataset.\n",
      "Swedish: 0.896 ± 0.075\n",
      "Danish: 0.843 ± 0.109\n",
      "Norwegian Bokmål: 0.846 ± 0.108\n",
      "Norwegian Nynorsk: 0.829 ± 0.117\n",
      "Faroese: 0.726 ± 0.128\n",
      "Icelandic: 0.717 ± 0.132\n",
      "Average: 0.782 ± 0.137\n"
     ]
    }
   ],
   "source": [
    "from src import CosineSimilarity\n",
    "\n",
    "sv_cos_sim, sv_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(sv_token_embedings_1), sv_token_embedings_2)\n",
    "da_cos_sim, da_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(da_token_embedings_1), da_token_embedings_2)\n",
    "nb_cos_sim, nb_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(nb_token_embedings_1), nb_token_embedings_2)\n",
    "nn_cos_sim, nn_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(nn_token_embedings_1), nn_token_embedings_2)\n",
    "fo_cos_sim, fo_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(fo_token_embedings_1), fo_token_embedings_2)\n",
    "is_cos_sim, is_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(is_token_embedings_1), is_token_embedings_2)\n",
    "\n",
    "all_token_embeddings_1 = np.concatenate((sv_token_embedings_1,da_token_embedings_1,nb_token_embedings_1,nn_token_embedings_1,fo_token_embedings_1,is_token_embedings_1), axis=0)\n",
    "all_token_embeddings_2 = np.concatenate((sv_token_embedings_2,da_token_embedings_2,nb_token_embedings_2,nn_token_embedings_2,fo_token_embedings_2,is_token_embedings_2), axis=0)\n",
    "\n",
    "all_cos_sim, all_stdev = CosineSimilarity.cosine_similarity_with_stdev(mlp_regressor.predict(all_token_embeddings_1), all_token_embeddings_2)\n",
    "\n",
    "print(\"Cosine similarity when testing MLP on Flores 200 devtest dataset.\")\n",
    "\n",
    "print(f\"Swedish: {round(sv_cos_sim, 3)} ± {round(sv_stdev, 3)}\")\n",
    "print(f\"Danish: {round(da_cos_sim, 3)} ± {round(da_stdev, 3)}\")\n",
    "print(f\"Norwegian Bokmål: {round(nb_cos_sim, 3)} ± {round(nb_stdev, 3)}\")\n",
    "print(f\"Norwegian Nynorsk: {round(nn_cos_sim, 3)} ± {round(nn_stdev, 3)}\")\n",
    "print(f\"Faroese: {round(fo_cos_sim, 3)} ± {round(fo_stdev, 3)}\")\n",
    "print(f\"Icelandic: {round(is_cos_sim, 3)} ± {round(is_stdev, 3)}\")\n",
    "print(f\"Average: {round(all_cos_sim, 3)} ± {round(all_stdev, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31b96e1",
   "metadata": {},
   "source": [
    "### Measure Euclidean distance on FLORES-200 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9df29807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eucledian distance when testing MLP on Flores 200 devtest dataset.\n",
      "Swedish: 0.493 ± 0.217\n",
      "Danish: 0.641 ± 0.318\n",
      "Norwegian Bokmål: 0.645 ± 0.335\n",
      "Norwegian Nynorsk: 0.686 ± 0.343\n",
      "Faroese: 0.963 ± 0.36\n",
      "Icelandic: 0.996 ± 0.36\n",
      "Average: 0.813 ± 0.387\n"
     ]
    }
   ],
   "source": [
    "from src import EuclideanDistance \n",
    "\n",
    "sv_euc_sim, sv_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(sv_token_embedings_1), sv_token_embedings_2)\n",
    "da_euc_sim, da_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(da_token_embedings_1), da_token_embedings_2)\n",
    "nb_euc_sim, nb_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(nb_token_embedings_1), nb_token_embedings_2)\n",
    "nn_euc_sim, nn_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(nn_token_embedings_1), nn_token_embedings_2)\n",
    "fo_euc_sim, fo_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(fo_token_embedings_1), fo_token_embedings_2)\n",
    "is_euc_sim, is_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(is_token_embedings_1), is_token_embedings_2)\n",
    "\n",
    "all_token_embeddings_1 = np.concatenate((sv_token_embedings_1,da_token_embedings_1,nb_token_embedings_1,nn_token_embedings_1,fo_token_embedings_1,is_token_embedings_1), axis=0)\n",
    "all_token_embeddings_2 = np.concatenate((sv_token_embedings_2,da_token_embedings_2,nb_token_embedings_2,nn_token_embedings_2,fo_token_embedings_2,is_token_embedings_2), axis=0)\n",
    "\n",
    "all_euc_sim, all_euc_stdev = EuclideanDistance.relative_euclidean_distance_stdev(mlp_regressor.predict(all_token_embeddings_1), all_token_embeddings_2)\n",
    "\n",
    "print(\"Eucledian distance when testing MLP on Flores 200 devtest dataset.\")\n",
    "\n",
    "print(f\"Swedish: {round(sv_euc_sim, 3)} ± {round(sv_euc_stdev, 3)}\")\n",
    "print(f\"Danish: {round(da_euc_sim, 3)} ± {round(da_euc_stdev, 3)}\")\n",
    "print(f\"Norwegian Bokmål: {round(nb_euc_sim, 3)} ± {round(nb_euc_stdev, 3)}\")\n",
    "print(f\"Norwegian Nynorsk: {round(nn_euc_sim, 3)} ± {round(nn_euc_stdev, 3)}\")\n",
    "print(f\"Faroese: {round(fo_euc_sim, 3)} ± {round(fo_euc_stdev, 3)}\")\n",
    "print(f\"Icelandic: {round(is_euc_sim, 3)} ± {round(is_euc_stdev, 3)}\")\n",
    "print(f\"Average: {round(all_euc_sim, 3)} ± {round(all_euc_stdev, 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
